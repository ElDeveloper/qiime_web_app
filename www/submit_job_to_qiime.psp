<%
__author__ = "Doug Wendel"
__copyright__ = "Copyright 2009-2010, Qiime Web Analysis"
__credits__ = ["Doug Wendel"]
__license__ = "GPL"
__version__ = "1.0.0.dev"
__maintainer__ = ["Doug Wendel"]
__email__ = "wendel@colorado.edu"
__status__ = "Development"
%>

<%
from data_access_connections import data_access_factory
from enums import DataAccessType
import os

def submitJob(study_id, user_id, output_dir, mapping_file, sff_files, data_access):
    # Set up the parameters
    params = []
    params.append('Mapping=%s' % mapping_file)
    params.append('Output=%s' % output_dir)
    params.append('SFF=%s' % ','.join(sff_files))
    job_input = '!!'.join(params)

    # Submit the job
    job_id = data_access.createTorqueJob('ProcessSFFHandler', job_input, user_id, study_id)
    
    # Make sure a legit job_id was created. If not, inform the user there was a problem
    if job_id < 0:
        req.write('<p/>There was an error creating the job. Please contact the system administratorx.')

def writeMappingFiles(study_id, data_access):
    # Get a list of result sets, one per run_prefix found in the stuyd
    mapping_file_header, result_sets = data_access.getSplitLibrariesMappingFileData(study_id)
    
    # For each result set returned, create a mapping file
    for run_prefix in result_sets:
        # Unpack the result set
        results = result_sets[run_prefix]
        
        # Create new mapping file in filesystem
        mapping_file_dir = sess['mapping_file_dir']
        if not os.path.exists(mapping_file_dir):
            os.makedirs(mapping_file_dir)

        # Create the new mapping file for this run_prefix
        mapping_file = file(os.path.join(mapping_file_dir, '%s__split_libraries_mapping_file.txt' % run_prefix), 'w')

        # Write the header row
        mapping_file.write(mapping_file_header + '\n')

        # Write out out the rows for this file
        for row in results:
            # Can't use something like '\t'.join(row) because not all items in list
            # are string values, hence the explicit loop structure here.
            to_write = ''
            for column in row:
                val = str(column)
                if val == 'None':
                    val = ''
                to_write += val + '\t'
                
            # Write the row minus the last tab
            mapping_file.write(to_write[0:len(to_write)-1] + '\n')

        mapping_file.close()

        # Add to the database list
        data_access.addMappingFile(study_id, mapping_file.name)
        
    # Finally, return a list of all created mapping files
    mapping_files = data_access.getMappingFiles(study_id)
    return mapping_files

def submitJobsToQiime(study_id, user_id, output_dir):
    # Instantiate one copy of data access for this process
    data_access = data_access_factory(DataAccessType.qiime_production)
    
    # Get the SFF files associated to this study
    sff_files = data_access.getSFFFiles(study_id)
    
    # Generate the mapping files
    mapping_files = writeMappingFiles(study_id, data_access)
    
    # Figure out which mapping file pairs with each SFF file
    file_map = {}
    for mapping_file in mapping_files:
        # Skip the mapping file if it's not of the correct naming format
        if len(mapping_file.split('__')) != 2:
            continue
            
        run_prefix = os.path.basename(mapping_file).split('__')[0]
        matching_sff_files = []
        
        for sff_file in sff_files:
            sff_file_basename = os.path.splitext(os.path.basename(sff_file))[0]
            
            # If the run_prefix matches the SFF file name exactly, assume only
            # one SFF for this run
            if run_prefix == os.path.splitext(sff_file_basename)[0]:
                matching_sff_files.append(sff_file)
                file_map[mapping_file] = matching_sff_files
                continue
                
            # If the run_prefix is contained in the file name, find all that match
            # and submit them together with the current mapping file
            elif run_prefix in sff_file_basename:
                # If it's the first item for this mapping file name, assign the list
                if not file_map.get(mapping_file):
                    file_map[mapping_file] = matching_sff_files
                file_map[mapping_file].append(sff_file)
            # If we get here, there are extra SFF files with no matching mapping file. 
            # For now, do nothing... may need to add some handling code at a later date.
            else:
                pass
    
    # raise Exception(str(file_map))
    # Submit jobs to the queue
    for mapping_file in file_map:
        submitJob(study_id, user_id, output_dir, mapping_file, file_map[mapping_file], data_access)

# Gather necessary values to create a new queue job
study_id = int(sess['study_id'])
user_id = int(sess['web_app_user_id'])
output_dir = sess['study_dir']

# Submit the jobs
submitJobsToQiime(study_id, user_id, output_dir)

# Redirect to the home page for this study
psp.redirect('fusebox.psp?page=select_study_task.psp')
%>


